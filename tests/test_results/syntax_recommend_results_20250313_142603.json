{
    "semantic_similarity": 0.5530981063842774,
    "syntax_similarity": 0.5078037564453848,
    "recommended_prompt": "<instructions>\n        1. **Objective**: Create a structured prompt to instruct an LLM to transform the provided \"Inputs\" into the exact format of the \"Desired Outputs.\"\n        2. **Use of Tags**: Ensure each section of your prompt is wrapped with the appropriate XML tags: \n            - Wrap instructions in &lt;instructions&gt;...&lt;/instructions&gt; \n            - Wrap steps in &lt;steps&gt;...&lt;/steps&gt; \n            - Wrap examples in &lt;example&gt;...&lt;/example&gt; \n            - Wrap the final system prompt in &lt;prompt&gt;...&lt;/prompt&gt; \n        3. **Maintain Structure**: Follow the specified XML tags consistently to ensure clarity and parseability.\n        4. **Independent Processing**: Treat each input-output pair as independent, ensuring that no input is merged or inferred with another.\n        5. **Use of {input_data} Placeholder**: Use the placeholder {input_data} **only** for variables that need to be substituted dynamically. Ensure that each row's data is processed independently, but avoid using the placeholder for fixed data or values that do not change between rows.\n        6. **Output Fidelity**: The output should exactly match the \"Desired Outputs,\" including syntax, spacing, and characters, with no deviations or added commentary.\n    </instructions>\n    <steps>\n        1. Analyze each row in \"Inputs\" and map it to the corresponding format specified in \"Desired Outputs.\"\n        2. Use the placeholder {input_data} **only** for variables that need to be substituted dynamically. Avoid using this placeholder for fixed values or data that will not change between rows unless it is used in \"Desired Outputs\".\n        3. Ensure each output follows the same syntax, spacing, and special characters as the \"Desired Outputs.\"\n        4. Utilize information in context since there might be important information the user is specifying.\n        5. The **generated system prompt must be wrapped in the &lt;prompt&gt;...&lt;/prompt&gt; tags**.\n        6. Do not include any commentary, explanations, or metadata\u2014just the final system prompt in the required structure.\n    </steps>\n    <example>\n        Inputs: `0 EU rejects German call to boycott British lamb... 1 Rare Hendrix song draft sells for almost $ 17,... Name: input_data, dtype: object`\n        Desired Outputs: `0 [\"Token: EU, NER_tag: B-ORG\", \"Token: rejects,... 1 [\"Token: Rare, NER_tag: O\", \"Token: Hendrix, N... Name: desired_output, dtype: object`\n    </example>\n    <context>\n        **Context**: Input data is raw tokenized text, and the desired output consists of tokens with their Named Entity Recognition label. The Tokens are labeled under one of the following labels [I-LOC, B-ORG, O, B-PER, I-PER, I-MISC, B-MISC, I-ORG, B-LOC]. The goal is to label all the tokens with its NER label.\n    </context>",
    "prompt_outputs": [
        "```xml\n<instructions>\n  Create a structured output that labels each token of the provided input text with its corresponding Named Entity Recognition (NER) tag according to the specified formats.\n</instructions>\n<steps>\n  1. Analyze the provided input data and identify each token along with its associated NER label based on its context in the sentence.\n  2. Ensure that each token is labeled with the appropriate NER tag: [I-LOC, B-ORG, O, B-PER, I-PER, I-MISC, B-MISC, I-ORG, B-LOC].\n  3. Format the output so that it matches the desired output syntax precisely, including the use of square brackets and quotation marks.\n  4. Ensure that no commentary or explanations are included in the output, only the formatted tweet with the appropriate labels.\n</steps>\n<example>\n  Inputs: `China says Taiwan spoils atmosphere for talks ...`\n  Desired Outputs: `[\"Token: China, NER_tag: B-ORG\", \"Token: says, NER_tag: O\", \"Token: Taiwan, NER_tag: B-LOC\", ...]`\n</example>\n<prompt>\n[\"Token: China, NER_tag: B-ORG\", \"Token: says, NER_tag: O\", \"Token: Taiwan, NER_tag: B-LOC\", \"Token: spoils, NER_tag: O\", \"Token: atmosphere, NER_tag: O\", \"Token: for, NER_tag: O\", \"Token: talks, NER_tag: O\", \".\", \"Token: BEIJING, NER_tag: B-LOC\", \"Token: 1996-08-22, NER_tag: O\", \"Token: China, NER_tag: B-ORG\", \"Token: on, NER_tag: O\", \"Token: Thursday, NER_tag: O\", \"Token: accused, NER_tag: O\", \"Token: Taipei, NER_tag: B-ORG\", \"Token: of, NER_tag: O\", \"Token: spoiling, NER_tag: O\", \"Token: the, NER_tag: O\", \"Token: atmosphere, NER_tag: O\", \"Token: for, NER_tag: O\", \"Token: a, NER_tag: O\", \"Token: resumption, NER_tag: O\", \"Token: of, NER_tag: O\", \"Token: talks, NER_tag: O\", \"Token: across, NER_tag: O\", \"Token: the, NER_tag: O\", \"Token: Taiwan, NER_tag: B-LOC\", \"Token: Strait, NER_tag: I-LOC\", \"Token: with, NER_tag: O\", \"Token: a, NER_tag: O\", \"Token: visit, NER_tag: O\", \"Token: to, NER_tag: O\", \"Token: Ukraine, NER_tag: B-LOC\", \"Token: by, NER_tag: O\", \"Token: Taiwanese, NER_tag: O\", \"Token: Vice, NER_tag: O\", \"Token: President, NER_tag: O\", \"Token: Lien, NER_tag: B-PER\", \"Token: Chan, NER_tag: I-PER\", \"Token: this, NER_tag: O\", \"Token: week, NER_tag: O\", \"Token: that, NER_tag: O\", \"Token: infuriated, NER_tag: O\", \"Token: Beijing, NER_tag: B-ORG\", \"Token: ., NER_tag: O\", \"Token: Speaking, NER_tag: O\", \"Token: only, NER_tag: O\", \"Token: hours, NER_tag: O\", \"Token: after, NER_tag: O\", \"Token: Chinese, NER_tag: B-ORG\", \"Token: state, NER_tag: O\", \"Token: media, NER_tag: O\", \"Token: said, NER_tag: O\", \"Token: the, NER_tag: O\", \"Token: time, NER_tag: O\", \"Token: was, NER_tag: O\", \"Token: right, NER_tag: O\", \"Token: to, NER_tag: O\", \"Token: engage, NER_tag: O\", \"Token: in, NER_tag: O\", \"Token: political, NER_tag: O\", \"Token: talks, NER_tag: O\", \"Token: with, NER_tag: O\", \"Token: Taiwan, NER_tag: B-LOC\", \"Token: ., NER_tag: O\", \"Token: Foreign, NER_tag: O\", \"Token: Ministry, NER_tag: B-ORG\", \"Token: spokesman, NER_tag: O\", \"Token: Shen, NER_tag: B-PER\", \"Token: Guofang, NER_tag: I-PER\", \"Token: told, NER_tag: O\", \"Token: Reuters, NER_tag: B-ORG\", \"Token: :, NER_tag: O\", \"Token: The, NER_tag: O\", \"Token: necessary, NER_tag: O\", \"Token: atmosphere, NER_tag: O\", \"Token: for, NER_tag: O\", \"Token: the, NER_tag: O\", \"Token: opening, NER_tag: O\", \"Token: of, NER_tag: O\", \"Token: the, NER_tag: O\", \"Token: talks, NER_tag: O\", \"Token: has, NER_tag: O\", \"Token: been, NER_tag: O\", \"Token: disrupted, NER_tag: O\", \"Token: by, NER_tag: O\", \"Token: the, NER_tag: O\", \"Token: Taiwan, NER_tag: B-LOC\", \"Token: authorities, NER_tag: O\", \"Token: ., NER_tag: O\", \"Token: State, NER_tag: B-ORG\", \"Token: media, NER_tag: O\", \"Token: quoted, NER_tag: O\", \"Token: China, NER_tag: B-ORG\", \"Token: 's, NER_tag: O\", \"Token: top, NER_tag: O\", \"Token: negotiator, NER_tag: O\", \"Token: with, NER_tag: O\", \"Token: Taipei, NER_tag: B-ORG\", \"Token: , NER_tag: O\", \"Token: Tang, NER_tag: B-PER\", \"Token: Shubei, NER_tag: I-PER\", \"Token: , NER_tag: O\", \"Token: as, NER_tag: O\", \"Token: telling, NER_tag: O\", \"Token: a, NER_tag: O\", \"Token: visiting, NER_tag: O\", \"Token: group, NER_tag: O\", \"Token: from, NER_tag: O\", \"Token: Taiwan, NER_tag: B-LOC\", \"Token: on, NER_tag: O\", \"Token: Wednesday, NER_tag: O\", \"Token: that, NER_tag: O\", \"Token: it, NER_tag: O\", \"Token: was, NER_tag: O\", \"Token: time, NER_tag: O\", \"Token: for, NER_tag: O\", \"Token: the, NER_tag: O\", \"Token: rivals, NER_tag: O\", \"Token: to, NER_tag: O\", \"Token: hold, NER_tag: O\", \"Token: political, NER_tag: O\", \"Token: talks, NER_tag: O\", \"Token: . , NER_tag: O\"]\n</prompt>\n```",
        "<prompt>\n[\"Token: China, NER_tag: B-ORG\", \"Token: says, NER_tag: O\", \"Token: time, NER_tag: O\", \"Token: right, NER_tag: O\", \"Token: for, NER_tag: O\", \"Token: Taiwan, NER_tag: B-LOC\", \"Token: talks, NER_tag: O\", \"Token: ., NER_tag: O\", \"Token: BEIJING, NER_tag: B-LOC\", \"Token: 1996-08-22, NER_tag: O\", \"Token: China, NER_tag: B-ORG\", \"Token: has, NER_tag: O\", \"Token: said, NER_tag: O\", \"Token: it, NER_tag: O\", \"Token: was, NER_tag: O\", \"Token: time, NER_tag: O\", \"Token: for, NER_tag: O\", \"Token: political, NER_tag: O\", \"Token: talks, NER_tag: O\", \"Token: with, NER_tag: O\", \"Token: Taiwan, NER_tag: B-LOC\", \"Token: and, NER_tag: O\", \"Token: that, NER_tag: O\", \"Token: the, NER_tag: O\", \"Token: rival, NER_tag: O\", \"Token: island, NER_tag: O\", \"Token: should, NER_tag: O\", \"Token: take, NER_tag: O\", \"Token: practical, NER_tag: O\", \"Token: steps, NER_tag: O\", \"Token: towards, NER_tag: O\", \"Token: that, NER_tag: O\", \"Token: goal, NER_tag: O\", \"Token: ., NER_tag: O\", \"Token: Consultations, NER_tag: O\", \"Token: should, NER_tag: O\", \"Token: be, NER_tag: O\", \"Token: held, NER_tag: O\", \"Token: to, NER_tag: O\", \"Token: set, NER_tag: O\", \"Token: the, NER_tag: O\", \"Token: time, NER_tag: O\", \"Token: and, NER_tag: O\", \"Token: format, NER_tag: O\", \"Token: of, NER_tag: O\", \"Token: the, NER_tag: O\", \"Token: talks, NER_tag: O\", \"Token: ,, NER_tag: O\", \"Token: the, NER_tag: O\", \"Token: official, NER_tag: O\", \"Token: Xinhua, NER_tag: B-ORG\", \"Token: news, NER_tag: O\", \"Token: agency, NER_tag: O\", \"Token: quoted, NER_tag: O\", \"Token: Tang, NER_tag: B-PER\", \"Token: Shubei, NER_tag: I-PER\", \"Token: ,, NER_tag: O\", \"Token: executive, NER_tag: O\", \"Token: vice, NER_tag: O\", \"Token: chairman, NER_tag: O\", \"Token: of, NER_tag: O\", \"Token: the, NER_tag: O\", \"Token: Association, NER_tag: B-ORG\", \"Token: for, NER_tag: O\", \"Token: Relations, NER_tag: I-ORG\", \"Token: Across, NER_tag: I-ORG\", \"Token: the, NER_tag: O\", \"Token: Taiwan, NER_tag: B-LOC\", \"Token: Straits, NER_tag: I-LOC\", \"Token: ,, NER_tag: O\", \"Token: as, NER_tag: O\", \"Token: saying, NER_tag: O\", \"Token: late, NER_tag: O\", \"Token: on, NER_tag: O\", \"Token: Wednesday, NER_tag: O\", \"Token: ., NER_tag: O\"]\n</prompt>",
        "```xml\n<instructions> \n1. **Objective**: Create a structured prompt for an LLM to transform the provided \"Inputs\" into the exact format of the \"Desired Outputs.\"\n2. **Use of Tags**: Wrap instructions in &lt;instructions&gt;...&lt;/instructions&gt;, steps in &lt;steps&gt;...&lt;/steps&gt;, examples in &lt;example&gt;...&lt;/example&gt;, and the final system prompt in &lt;prompt&gt;...&lt;/prompt&gt;.\n3. **Maintain Structure**: Follow the specified XML tags consistently for clarity and parseability.\n4. **Independent Processing**: Treat each input-output pair as independent, ensuring that no input is merged or inferred with another.\n5. **Use of {input_data} Placeholder**: Use {input_data} only for variables that need dynamic substitution. Do not use it for fixed data or values that do not change between rows.\n6. **Output Fidelity**: Ensure the output exactly matches the \"Desired Outputs,\" including syntax, spacing, and characters, with no deviations or added commentary.\n</instructions>\n<steps> \n1. Analyze each row in \"Inputs\" and map it to the corresponding format specified in \"Desired Outputs.\"\n2. Use the placeholder {input_data} only for dynamic variables. Avoid using this placeholder for fixed values or data not changing between rows.\n3. Ensure each output follows the syntax, spacing, and special characters present in the \"Desired Outputs.\"\n4. Utilize context information, as there may be important details specified by the user.\n5. The generated system prompt must be wrapped in &lt;prompt&gt;...&lt;/prompt&gt; tags.\n6. Do not include commentary, explanations, or metadata\u2014just the final system prompt in the required structure.\n</steps>\n<example> \nInputs: `0 German July car registrations up 14.2 pct yr / yr ... 1 FRANKFURT 1996-08-22 German first-time registrations ... Name: input_data, dtype: object` \nDesired Outputs: `0 [\"Token: German, NER_tag: B-LOC\", \"Token: July, NER_tag: O\", ... 1 [\"Token: FRANKFURT, NER_tag: B-LOC\", \"Token: 1996-08-22, NER_tag: O\", ... Name: desired_output, dtype: object` \n</example>\n<context> \n**Context**: Input data is raw tokenized text, and the desired output consists of tokens with their Named Entity Recognition label. Labels include [I-LOC, B-ORG, O, B-PER, I-PER, I-MISC, B-MISC, I-ORG, B-LOC]. The goal is to label all tokens with their NER label.\n</context>\n<prompt> \nTransform the following input into the desired output format: \n{input_data} \n</prompt>\n```",
        "```xml\n<prompt>\n    <instructions>\n        Create a structured output for the following input text with tokens labeled with their Named Entity Recognition (NER) tags according to the specified format.\n    </instructions>\n    <steps>\n        1. Analyze the input text \"GREEK SOCIALISTS GIVE GREEN LIGHT TO PM FOR ELECTIONS . ATHENS 1996-08-22 The Greek socialist party 's executive bureau gave the green light to Prime Minister Costas Simitis to call snap elections , its general secretary Costas Skandalidis told reporters . Prime Minister Costas Simitis is going to make an official announcement after a cabinet meeting later on Thursday , said Skandalidis . -- Dimitris Kontogiannis , Athens Newsroom +301 3311812-4\" and extract tokens.\n        2. Assign NER labels to each token based on the provided categories (I-LOC, B-ORG, O, B-PER, I-PER, I-MISC, B-MISC, I-ORG, B-LOC).\n        3. Format the output according to the pattern: [\"Token: <token>, NER_tag: <label>\", ...].\n    </steps>\n    <example>\n        Inputs: `GREEK SOCIALISTS GIVE GREEN LIGHT TO PM FOR ELECTIONS . ATHENS 1996-08-22 The Greek socialist party 's executive bureau gave the green light to Prime Minister Costas Simitis to call snap elections , its general secretary Costas Skandalidis told reporters . Prime Minister Costas Simitis is going to make an official announcement after a cabinet meeting later on Thursday , said Skandalidis . -- Dimitris Kontogiannis , Athens Newsroom +301 3311812-4`\n        Desired Outputs: `[\"Token: GREEK, NER_tag: B-LOC\", \"Token: SOCIALISTS, NER_tag: B-ORG\", \"Token: GIVE, NER_tag: O\", \"Token: GREEN, NER_tag: O\", \"Token: LIGHT, NER_tag: O\", \"Token: TO, NER_tag: O\", \"Token: PM, NER_tag: O\", \"Token: FOR, NER_tag: O\", \"Token: ELECTIONS, NER_tag: O\", \"Token: ., NER_tag: O\", \"Token: ATHENS, NER_tag: B-LOC\", \"Token: 1996-08-22, NER_tag: O\", \"Token: The, NER_tag: O\", \"Token: Greek, NER_tag: B-LOC\", \"Token: socialist, NER_tag: I-ORG\", \"Token: party, NER_tag: O\", \"Token: 's, NER_tag: O\", \"Token: executive, NER_tag: O\", \"Token: bureau, NER_tag: O\", \"Token: gave, NER_tag: O\", \"Token: the, NER_tag: O\", \"Token: green, NER_tag: O\", \"Token: light, NER_tag: O\", \"Token: to, NER_tag: O\", \"Token: Prime, NER_tag: B-PER\", \"Token: Minister, NER_tag: I-PER\", \"Token: Costas, NER_tag: B-PER\", \"Token: Simitis, NER_tag: I-PER\", \"Token: to, NER_tag: O\", \"Token: call, NER_tag: O\", \"Token: snap, NER_tag: O\", \"Token: elections, NER_tag: O\", \"Token: ,, NER_tag: O\", \"Token: its, NER_tag: O\", \"Token: general, NER_tag: O\", \"Token: secretary, NER_tag: O\", \"Token: Costas, NER_tag: B-PER\", \"Token: Skandalidis, NER_tag: I-PER\", \"Token: told, NER_tag: O\", \"Token: reporters, NER_tag: O\", \"Token: ., NER_tag: O\", \"Token: Prime, NER_tag: B-PER\", \"Token: Minister, NER_tag: I-PER\", \"Token: Costas, NER_tag: B-PER\", \"Token: Simitis, NER_tag: I-PER\", \"Token: is, NER_tag: O\", \"Token: going, NER_tag: O\", \"Token: to, NER_tag: O\", \"Token: make, NER_tag: O\", \"Token: an, NER_tag: O\", \"Token: official, NER_tag: O\", \"Token: announcement, NER_tag: O\", \"Token: after, NER_tag: O\", \"Token: a, NER_tag: O\", \"Token: cabinet, NER_tag: O\", \"Token: meeting, NER_tag: O\", \"Token: later, NER_tag: O\", \"Token: on, NER_tag: O\", \"Token: Thursday, NER_tag: O\", \"Token: ,, NER_tag: O\", \"Token: said, NER_tag: O\", \"Token: Skandalidis, NER_tag: B-PER\", \"Token: ., NER_tag: O\", \"Token: --, NER_tag: O\", \"Token: Dimitris, NER_tag: B-PER\", \"Token: Kontogiannis, NER_tag: I-PER\", \"Token: ,, NER_tag: O\", \"Token: Athens, NER_tag: B-LOC\", \"Token: Newsroom, NER_tag: O\", \"Token: +301, NER_tag: O\", \"Token: 3311812-4, NER_tag: O\"]`\n    </example>\n</prompt>\n```",
        "```xml\n<prompt> \n    Transform the provided input data into the specified format with Named Entity Recognition labels.\n    Input: {input_data}\n    Output: [\"Token: BayerVB, NER_tag: O\", \"Token: sets, NER_tag: O\", \"Token: C$, NER_tag: O\", \"Token: 100, NER_tag: O\", \"Token: million, NER_tag: O\", \"Token: six-year, NER_tag: O\", \"Token: bond, NER_tag: O\", \"Token: ., NER_tag: O\", \"Token: LONDON, NER_tag: B-LOC\", \"Token: 1996-08-22, NER_tag: O\", \"Token: The, NER_tag: O\", \"Token: following, NER_tag: O\", \"Token: bond, NER_tag: O\", \"Token: was, NER_tag: O\", \"Token: announced, NER_tag: O\", \"Token: by, NER_tag: O\", \"Token: lead, NER_tag: O\", \"Token: manager, NER_tag: O\", \"Token: Toronto, NER_tag: B-LOC\", \"Token: Dominion, NER_tag: I-ORG\", \"Token: ., NER_tag: O\", \"Token: BORROWER, NER_tag: O\", \"Token: BAYERISCHE, NER_tag: B-ORG\", \"Token: VEREINSBANK, NER_tag: I-ORG\", \"Token: AMT, NER_tag: O\", \"Token: C$, NER_tag: O\", \"Token: 100, NER_tag: O\", \"Token: MLN, NER_tag: O\", \"Token: COUPON, NER_tag: O\", \"Token: 6.625, NER_tag: O\", \"Token: MATURITY, NER_tag: O\", \"Token: 24.SEP.02, NER_tag: O\", \"Token: TYPE, NER_tag: O\", \"Token: STRAIGHT, NER_tag: O\", \"Token: ISS, NER_tag: O\", \"Token: PRICE, NER_tag: O\", \"Token: 100.92, NER_tag: O\", \"Token: PAY, NER_tag: O\", \"Token: DATE, NER_tag: O\", \"Token: 24.SEP.96, NER_tag: O\", \"Token: FULL, NER_tag: O\", \"Token: FEES, NER_tag: O\", \"Token: 1.875, NER_tag: O\", \"Token: REOFFER, NER_tag: O\", \"Token: 99.32, NER_tag: O\", \"Token: SPREAD, NER_tag: O\", \"Token: +20, NER_tag: O\", \"Token: BP, NER_tag: O\", \"Token: MOODY, NER_tag: O\", \"Token: AA1, NER_tag: O\", \"Token: LISTING, NER_tag: O\", \"Token: LUX, NER_tag: B-LOC\", \"Token: PAY, NER_tag: O\", \"Token: FREQ, NER_tag: O\", \"Token: =, NER_tag: O\", \"Token: S&amp;P, NER_tag: O\", \"Token: =, NER_tag: O\", \"Token: DENOMS, NER_tag: O\", \"Token: (, NER_tag: O\", \"Token: K, NER_tag: O\", \"Token: ), NER_tag: O\", \"Token: 1-10-100, NER_tag: O\", \"Token: SALE, NER_tag: O\", \"Token: LIMITS, NER_tag: O\", \"Token: US, NER_tag: B-LOC\", \"Token: /, NER_tag: O\", \"Token: UK, NER_tag: B-LOC\", \"Token: /, NER_tag: O\", \"Token: CA, NER_tag: B-LOC\", \"Token: NEG, NER_tag: O\", \"Token: PLG, NER_tag: O\", \"Token: NO, NER_tag: O\", \"Token: CRS, NER_tag: O\", \"Token: DEFLT, NER_tag: O\", \"Token: NO, NER_tag: O\", \"Token: FORCE, NER_tag: O\", \"Token: MAJ, NER_tag: O\", \"Token: =, NER_tag: O\", \"Token: GOV, NER_tag: O\", \"Token: LAW, NER_tag: O\", \"Token: GERMAN, NER_tag: B-LOC\", \"Token: HOME, NER_tag: O\", \"Token: CTRY, NER_tag: O\", \"Token: =, NER_tag: O\", \"Token: TAX, NER_tag: O\", \"Token: PROVS, NER_tag: O\", \"Token: STANDARD, NER_tag: O\", \"Token: MGT, NER_tag: O\", \"Token: /, NER_tag: O\", \"Token: UND, NER_tag: O\", \"Token: 0.275, NER_tag: O\", \"Token: SELL, NER_tag: O\", \"Token: CONC, NER_tag: O\", \"Token: 1.60, NER_tag: O\", \"Token: PRAECIP, NER_tag: O\", \"Token: =, NER_tag: O\", \"Token: UNDERLYING, NER_tag: O\", \"Token: GOVT, NER_tag: O\", \"Token: BOND, NER_tag: O\", \"Token: 7.0, NER_tag: O\", \"Token: PCT, NER_tag: O\", \"Token: SEPT, NER_tag: O\", \"Token: 2001, NER_tag: O\", \"Token: NOTES, NER_tag: O\", \"Token: BAYERISCHE, NER_tag: B-ORG\", \"Token: VEREINSBANK, NER_tag: I-ORG\", \"Token: IS, NER_tag: O\", \"Token: JOINT, NER_tag: O\", \"Token: LEAD, NER_tag: O\", \"Token: MANAGER, NER_tag: O\", \"Token: --, NER_tag: O\", \"Token: London, NER_tag: B-LOC\", \"Token: Newsroom, NER_tag: O\", \"Token: +44, NER_tag: O\", \"Token: 171, NER_tag: O\", \"Token: 542, NER_tag: O\", \"Token: 7658, NER_tag: O\"]\n</prompt>\n```",
        "```xml\n<instructions>\n1. Transform the provided {input_data} into labeled tokens with their Named Entity Recognition (NER) tags.\n2. Each token needs to have the following format: \"Token: {token_value}, NER_tag: {ner_label}\".\n3. Classify each token according to the following labels: [I-LOC, B-ORG, O, B-PER, I-PER, I-MISC, B-MISC, I-ORG, B-LOC].\n4. Ensure that the NER labels are accurate based on the content of the {input_data}.\n</instructions>\n<steps>\n1. Analyze the {input_data} and identify individual tokens.\n2. Assign the appropriate NER tag to each token based on the context of the input.\n3. Format each token and its corresponding NER tag according to the specified structure.\n4. Maintain consistency in syntax and spacing as illustrated in the examples.\n5. Compile all labeled tokens into a single list, ensuring each label is included for each token.\n</steps>\n<example>\n Inputs: `Venantius sets $ 300 million January 1999 FRN . LONDON 1996-08-22 The following floating-rate issue was announced by lead manager Lehman Brothers International . BORROWER VENANTIUS AB ( SWEDISH NATIONAL MORTGAGE AGENCY ) AMT $ 300 MLN SPREAD - 12.5 BP MATURITY 21.JAN.99 TYPE FRN BASE 3M LIBOR PAY DATE S23.SEP.96 LAST MOODY AA3 ISS PRICE 99.956 FULL FEES 10 BP LAST S&P AA+ REOFFER = NOTES S SHORT FIRST COUPON LISTING LONDON DENOMS ( K ) 1-10-100 SALE LIMITS US / UK / JP / FR NEG PLG YES CRS DEFLT NO FORCE MAJ IPMA 2 GOV LAW ENGLISH HOME CTRY SWEDEN TAX PROVS STANDARD MGT / UND 5 BP SELL CONC 5 BP PRAECIP = NOTES ISSUED OFF EMTN PROGRAMME --`\n Desired Outputs: `[\"Token: Venantius, NER_tag: B-ORG\", \"Token: sets, NER_tag: O\", \"Token: $, NER_tag: O\", \"Token: 300, NER_tag: O\", \"Token: million, NER_tag: O\", \"Token: January, NER_tag: B-LOC\", \"Token: 1999, NER_tag: O\", \"Token: FRN, NER_tag: O\", \"Token: ., NER_tag: O\", \"Token: LONDON, NER_tag: B-LOC\", \"Token: 1996-08-22, NER_tag: O\", ... ]`\n</example>\n<prompt>\nTransform the provided input data into a list of labeled tokens with their respective Named Entity Recognition (NER) tags using the format \"Token: {token_value}, NER_tag: {ner_label}\" while classifying each token according to the specified labels: [I-LOC, B-ORG, O, B-PER, I-PER, I-MISC, B-MISC, I-ORG, B-LOC]. Ensure the output matches the example structure precisely.\n</prompt>\n```",
        "```xml\n<prompt>\n    Transform the input {input_data} into the following format, applying the Named Entity Recognition (NER) tags to each token:\n    {input_data} = Port conditions update - Syria - Lloyds Shipping . Port conditions from Lloyds Shipping Intelligence Service -- LATTAKIA , Aug 10 - waiting time at Lattakia and Tartous presently 24 hours .\n    \n    0 [\"Token: Port, NER_tag: O\", \"Token: conditions, NER_tag: O\", \"Token: update, NER_tag: O\", \"Token: -, NER_tag: O\", \"Token: Syria, NER_tag: B-LOC\", \"Token: -, NER_tag: O\", \"Token: Lloyds, NER_tag: B-ORG\", \"Token: Shipping, NER_tag: I-ORG\", \"Token: ., NER_tag: O\", \"Token: Port, NER_tag: O\", \"Token: conditions, NER_tag: O\", \"Token: from, NER_tag: O\", \"Token: Lloyds, NER_tag: B-ORG\", \"Token: Shipping, NER_tag: I-ORG\", \"Token: Intelligence, NER_tag: O\", \"Token: Service, NER_tag: O\", \"Token: --, NER_tag: O\", \"Token: LATTAKIA, NER_tag: B-LOC\", \"Token: ,, NER_tag: O\", \"Token: Aug, NER_tag: O\", \"Token: 10, NER_tag: O\", \"Token: -, NER_tag: O\", \"Token: waiting, NER_tag: O\", \"Token: time, NER_tag: O\", \"Token: at, NER_tag: O\", \"Token: Lattakia, NER_tag: B-LOC\", \"Token: and, NER_tag: O\", \"Token: Tartous, NER_tag: B-LOC\", \"Token: presently, NER_tag: O\", \"Token: 24, NER_tag: O\", \"Token: hours, NER_tag: O\", \"Token: ., NER_tag: O\"]\n</prompt>\n```",
        "```xml\n<instructions>\n Create a structured prompt to transform the provided input data into a specific tokenized format with Named Entity Recognition labels. \n Ensure each section is clearly identified with XML tags as specified. Each input-output pair should be processed independently, \n following the required output structure with respect to spacing, syntax, and characters.\n</instructions>\n<steps>\n 1. Analyze the input data and extract individual tokens along with their corresponding Named Entity Recognition labels. \n 2. Use the placeholder {input_data} for dynamic substitution where necessary, ensuring that fixed values are not included.\n 3. Ensure the output format strictly adheres to the specified syntax and labeling.\n 4. Maintain the context of tokenization and NER labeling as driven by the example provided.\n 5. Wrap the final system prompt in <prompt>...</prompt> tags as specified.\n 6. Do not include any commentary, explanations, or metadata\u2014only the final system prompt should be included.\n</steps>\n<example>\n Inputs: `0 EU rejects German call to boycott British lamb... 1 Rare Hendrix song draft sells for almost $ 17,... Name: input_data, dtype: object`\n Desired Outputs: `0 [\"Token: EU, NER_tag: B-ORG\", \"Token: rejects,... 1 [\"Token: Rare, NER_tag: O\", \"Token: Hendrix, N... Name: desired_output, dtype: object`\n</example>\n<prompt>\n 0 [\"Token: Israel, NER_tag: B-LOC\", \"Token: plays, NER_tag: O\", \"Token: down, NER_tag: O\", \"Token: fears, NER_tag: O\", \"Token: of, NER_tag: O\", \"Token: war, NER_tag: O\", \"Token: with, NER_tag: O\", \"Token: Syria, NER_tag: B-LOC\", \"Token: . , NER_tag: O\", ...]\n</prompt>\n```",
        "```xml\n<instructions>\n  Create a transformation of the provided {input_data} into a structured format for Named Entity Recognition (NER) labels. Every token from the input should be captured with its corresponding NER tag, formatted exactly as shown in the examples.\n</instructions>\n<steps>\n  1. Identify each token in the {input_data} and map it to its appropriate NER tag based on the specified labels: [I-LOC, B-ORG, O, B-PER, I-PER, I-MISC, B-MISC, I-ORG, B-LOC].\n  2. Utilize the {input_data} placeholder dynamically for each row of input, ensuring the output aligns with the format of the desired outputs.\n  3. Ensure fidelity to the specified output syntax, spacing, and characters at all times.\n  4. Process each input independently, adhering strictly to the specified format without merging data from different rows.\n</steps>\n<example>\nInputs: `Polish diplomat denies nurses stranded in Libya . TUNIS 1996-08-22 A Polish diplomat on Thursday denied a Polish tabloid report this week that Libya was refusing exit visas to 100 Polish nurses trying to return home after working in the North African country . This is not true . Up to today , we have no knowledge of any nurse stranded or kept in Libya without her will , and we have not received any complaint , the Polish embassy 's charge d'affaires in Tripoli , Tadeusz Awdankiewicz , told Reuters by telephone . Poland 's labour ministry said this week it would send a team to Libya to investigate , but Awdankiewicz said the probe was prompted by some nurses complaining about`\nDesired Outputs: `[\"Token: Polish, NER_tag: B-ORG\", \"Token: diplomat, NER_tag: O\", \"Token: denies, NER_tag: O\", \"Token: nurses, NER_tag: O\", \"Token: stranded, NER_tag: O\", \"Token: in, NER_tag: O\", \"Token: Libya, NER_tag: B-LOC\", ...]`\n</example>\n<prompt>\nTransform {input_data} into the following format: \n[\"Token: Polish, NER_tag: B-ORG\", \"Token: diplomat, NER_tag: O\", \"Token: denies, NER_tag: O\", \"Token: nurses, NER_tag: O\", \"Token: stranded, NER_tag: O\", \"Token: in, NER_tag: O\", \"Token: Libya, NER_tag: B-LOC\", \"Token: ., NER_tag: O\", \"Token: TUNIS, NER_tag: B-LOC\", \"Token: 1996-08-22, NER_tag: O\", \"Token: A, NER_tag: O\", \"Token: Polish, NER_tag: B-ORG\", \"Token: diplomat, NER_tag: O\", \"Token: on, NER_tag: O\", \"Token: Thursday, NER_tag: O\", ...]\n</prompt>\n```",
        "```xml\n<instructions>\n1. **Objective**: Create a structured prompt to instruct an LLM to transform the provided \"Inputs\" into the exact format of the \"Desired Outputs.\"\n2. **Use of Tags**: Ensure each section of your prompt is wrapped with the appropriate XML tags: \n   - Wrap instructions in &lt;instructions&gt;...&lt;/instructions&gt;\n   - Wrap steps in &lt;steps&gt;...&lt;/steps&gt;\n   - Wrap examples in &lt;example&gt;...&lt;/example&gt;\n   - Wrap the final system prompt in &lt;prompt&gt;...&lt;/prompt&gt;\n3. **Maintain Structure**: Follow the specified XML tags consistently to ensure clarity and parseability.\n4. **Independent Processing**: Treat each input-output pair as independent, ensuring that no input is merged or inferred with another.\n5. **Use of {input_data} Placeholder**: Use the placeholder {input_data} **only** for variables that need to be substituted dynamically. Ensure that each row's data is processed independently, but avoid using the placeholder for fixed data or values that do not change between rows.\n6. **Output Fidelity**: The output should exactly match the \"Desired Outputs,\" including syntax, spacing, and characters, with no deviations or added commentary.\n</instructions>\n<steps>\n1. Analyze each row in \"Inputs\" and map it to the corresponding format specified in \"Desired Outputs.\"\n2. Use the placeholder {input_data} **only** for variables that need to be substituted dynamically. Avoid using this placeholder for fixed values or data that will not change between rows unless it is used in \"Desired Outputs\".\n3. Ensure each output follows the same syntax, spacing, and special characters as the \"Desired Outputs.\"\n4. Utilize information in context since there might be important information the user is specifying.\n5. The **generated system prompt must be wrapped in the &lt;prompt&gt;...&lt;/prompt&gt; tags**.\n6. Do not include any commentary, explanations, or metadata\u2014just the final system prompt in the required structure.\n</steps>\n<example>\nInputs: `Two Iranian opposition leaders meet in Baghdad. Hassan Hafidh BAGHDAD 1996-08-22 An Iranian exile group based in Iraq vowed on Thursday to extend support to Iran's Kurdish rebels after they were attacked by Iranian troops deep inside Iraq last month. A Mujahideen Khalq statement said its leader Massoud Rajavi met in Baghdad the Secretary-General of the Kurdistan Democratic Party of Iran (KDPI) Hassan Rastegar on Wednesday and voiced his support to Iran's rebel Kurds. Rajavi emphasised that the Iranian Resistance would continue to stand side by side with their Kurdish compatriots and the resistance movement in Iranian Kurdistan, it said. A spokesman for the group said the meeting signals a new level of cooperation`\nDesired Outputs: `[\"Token: Two, NER_tag: O\", \"Token: Iranian, NER_tag: B-MISC\", \"Token: opposition, NER_tag: O\", \"Token: leaders, NER_tag: O\", \"Token: meet, NER_tag: O\", \"Token: in, NER_tag: O\", \"Token: Baghdad, NER_tag: B-LOC\", \"Token: ., NER_tag: O\", ...]`\n</example>\n<prompt>\nTransform the input text \"{input_data}\" into a list of tokens with their corresponding Named Entity Recognition labels, formatted exactly as in the desired output.\n</prompt>\n```"
    ],
    "recommendation": "Optimize",
    "optimized_prompt": "<instructions>\n        1. **Objective**: Create a structured prompt to instruct an LLM to transform the provided \"Inputs\" into the exact format of the \"Desired Outputs.\"\n        2. **Use of Tags**: Ensure each section of your prompt is wrapped with the appropriate XML tags: \n            - Wrap instructions in &lt;instructions&gt;...&lt;/instructions&gt; \n            - Wrap steps in &lt;steps&gt;...&lt;/steps&gt; \n            - Wrap examples in &lt;example&gt;...&lt;/example&gt; \n            - Wrap the final system prompt in &lt;prompt&gt;...&lt;/prompt&gt; \n        3. **Maintain Structure**: Follow the specified XML tags consistently to ensure clarity and parseability.\n        4. **Independent Processing**: Treat each input-output pair as independent, ensuring that no input is merged or inferred with another.\n        5. **Use of {input_data} Placeholder**: Use the placeholder {input_data} **only** for variables that need to be substituted dynamically. Ensure that each row's data is processed independently, but avoid using the placeholder for fixed data or values that do not change between rows.\n        6. **Output Fidelity**: The output should exactly match the \"Desired Outputs,\" including syntax, spacing, and characters, with no deviations or added commentary.\n    </instructions>\n    <steps>\n        1. Analyze each row in \"Inputs\" and map it to the corresponding format specified in \"Desired Outputs.\"\n        2. Use the placeholder {input_data} **only** for variables that need to be substituted dynamically. Avoid using this placeholder for fixed values or data that will not change between rows unless it is used in \"Desired Outputs\".\n        3. Ensure each output follows the same syntax, spacing, and special characters as the \"Desired Outputs.\"\n        4. Utilize information in context since there might be important information the user is specifying.\n        5. The **generated system prompt must be wrapped in the &lt;prompt&gt;...&lt;/prompt&gt; tags**.\n        6. Do not include any commentary, explanations, or metadata\u2014just the final system prompt in the required structure.\n    </steps>\n    <example>\n        Inputs: `0 EU rejects German call to boycott British lamb... 1 Rare Hendrix song draft sells for almost $ 17,... Name: input_data, dtype: object`\n        Desired Outputs: `0 [\"Token: EU, NER_tag: B-ORG\", \"Token: rejects,... 1 [\"Token: Rare, NER_tag: O\", \"Token: Hendrix, N... Name: desired_output, dtype: object`\n    </example>\n    <context>\n        **Context**: Input data is raw tokenized text, and the desired output consists of tokens with their Named Entity Recognition label. The Tokens are labeled under one of the following labels [I-LOC, B-ORG, O, B-PER, I-PER, I-MISC, B-MISC, I-ORG, B-LOC]. The goal is to label all the tokens with its NER label.\n    </context>",
    "optimization_metrics": {
        "semantic_similarity": 0.43641809970140455,
        "syntactic_similarity": 0.49530990775925365,
        "evaluation_details": [
            "```xml\n<instructions>\n  1. **Objective**: Create a structured prompt to instruct an LLM to transform the provided \"Inputs\" into the exact format of the \"Desired Outputs.\"\n  2. **Use of Tags**: Ensure each section of your prompt is wrapped with the appropriate XML tags: \n    - Wrap instructions in &lt;instructions&gt;...&lt;/instructions&gt; \n    - Wrap steps in &lt;steps&gt;...&lt;/steps&gt; \n    - Wrap examples in &lt;example&gt;...&lt;/example&gt; \n    - Wrap the final system prompt in &lt;prompt&gt;...&lt;/prompt&gt; \n  3. **Maintain Structure**: Follow the specified XML tags consistently to ensure clarity and parseability. \n  4. **Independent Processing**: Treat each input-output pair as independent, ensuring that no input is merged or inferred with another. \n  5. **Use of {input_data} Placeholder**: Use the placeholder {input_data} **only** for variables that need to be substituted dynamically. Ensure that each row's data is processed independently, but avoid using the placeholder for fixed data or values that do not change between rows. \n  6. **Output Fidelity**: The output should exactly match the \"Desired Outputs,\" including syntax, spacing, and characters, with no deviations or added commentary.\n</instructions>\n<steps>\n  1. Analyze each row in \"Inputs\" and map it to the corresponding format specified in \"Desired Outputs.\"\n  2. Use the placeholder {input_data} **only** for variables that need to be substituted dynamically. Avoid using this placeholder for fixed values or data that will not change between rows unless it is used in \"Desired Outputs\".\n  3. Ensure each output follows the same syntax, spacing, and special characters as the \"Desired Outputs.\"\n  4. Utilize information in context since there might be important information the user is specifying.\n  5. The **generated system prompt must be wrapped in the &lt;prompt&gt;...&lt;/prompt&gt; tags**.\n  6. Do not include any commentary, explanations, or metadata\u2014just the final system prompt in the required structure.\n</steps>\n<example>\n Inputs: `2 China says Taiwan spoils atmosphere for talks. BEIJING 1996-08-22 China on Thursday accused Taipei of spoiling the atmosphere for a resumption of talks across the Taiwan Strait with a visit to Ukraine by Taiwanese Vice President Lien Chan this week that infuriated Beijing.`\n Desired Outputs: `2 [\"Token: China, NER_tag: B-ORG\", \"Token: says, NER_tag: O\", \"Token: Taiwan, NER_tag: B-LOC\", \"Token: spoils, NER_tag: O\", \"Token: atmosphere, NER_tag: O\", \"Token: for, NER_tag: O\", \"Token: talks, NER_tag: O\", \"Token: ., NER_tag: O\", \"Token: BEIJING, NER_tag: B-LOC\", \"Token: 1996-08-22, NER_tag: O\", \"Token: China, NER_tag: B-ORG\", \"Token: on, NER_tag: O\", \"Token: Thursday, NER_tag: O\", \"Token: accused, NER_tag: O\", \"Token: Taipei, NER_tag: B-LOC\", \"Token: of, NER_tag: O\", \"Token: spoiling, NER_tag: O\", \"Token: the, NER_tag: O\", \"Token: atmosphere, NER_tag: O\", \"Token: for, NER_tag: O\", \"Token: a, NER_tag: O\", \"Token: resumption, NER_tag: O\", \"Token: of, NER_tag: O\", \"Token: talks, NER_tag: O\", \"Token: across, NER_tag: O\", \"Token: the, NER_tag: O\", \"Token: Taiwan, NER_tag: B-LOC\", \"Token: Strait, NER_tag: I-LOC\", \"Token: with, NER_tag: O\", \"Token: a, NER_tag: O\", \"Token: visit, NER_tag: O\", \"Token: to, NER_tag: O\", \"Token: Ukraine, NER_tag: B-LOC\", \"Token: by, NER_tag: O\", \"Token: Taiwanese, NER_tag: O\", \"Token: Vice, NER_tag: O\", \"Token: President, NER_tag: O\", \"Token: Lien, NER_tag: B-PER\", \"Token: Chan, NER_tag: I-PER\", \"Token: this, NER_tag: O\", \"Token: week, NER_tag: O\", \"Token: that, NER_tag: O\", \"Token: infuriated, NER_tag: O\", \"Token: Beijing, NER_tag: B-LOC\", \"Token: ., NER_tag: O\"]`\n</example>\n<prompt>\nTransform the following input data into a structured output with the necessary Named Entity Recognition labels: {input_data}\n</prompt>\n```",
            "```xml\n<prompt>\n    [\"Token: China, NER_tag: B-LOC\", \"Token: says, NER_tag: O\", \"Token: time, NER_tag: O\", \"Token: right, NER_tag: O\", \"Token: for, NER_tag: O\", \"Token: Taiwan, NER_tag: B-LOC\", \"Token: talks, NER_tag: O\", \"Token: ., NER_tag: O\", \"Token: BEIJING, NER_tag: B-LOC\", \"Token: 1996-08-22, NER_tag: O\", \"Token: China, NER_tag: B-ORG\", \"Token: has, NER_tag: O\", \"Token: said, NER_tag: O\", \"Token: it, NER_tag: O\", \"Token: was, NER_tag: O\", \"Token: time, NER_tag: O\", \"Token: for, NER_tag: O\", \"Token: political, NER_tag: O\", \"Token: talks, NER_tag: O\", \"Token: with, NER_tag: O\", \"Token: Taiwan, NER_tag: B-LOC\", \"Token: and, NER_tag: O\", \"Token: that, NER_tag: O\", \"Token: the, NER_tag: O\", \"Token: rival, NER_tag: O\", \"Token: island, NER_tag: O\", \"Token: should, NER_tag: O\", \"Token: take, NER_tag: O\", \"Token: practical, NER_tag: O\", \"Token: steps, NER_tag: O\", \"Token: towards, NER_tag: O\", \"Token: that, NER_tag: O\", \"Token: goal, NER_tag: O\", \"Token: ., NER_tag: O\", \"Token: Consultations, NER_tag: O\", \"Token: should, NER_tag: O\", \"Token: be, NER_tag: O\", \"Token: held, NER_tag: O\", \"Token: to, NER_tag: O\", \"Token: set, NER_tag: O\", \"Token: the, NER_tag: O\", \"Token: time, NER_tag: O\", \"Token: and, NER_tag: O\", \"Token: format, NER_tag: O\", \"Token: of, NER_tag: O\", \"Token: the, NER_tag: O\", \"Token: talks, NER_tag: O\", \"Token: ,, NER_tag: O\", \"Token: the, NER_tag: O\", \"Token: official, NER_tag: O\", \"Token: Xinhua, NER_tag: B-ORG\", \"Token: news, NER_tag: O\", \"Token: agency, NER_tag: O\", \"Token: quoted, NER_tag: O\", \"Token: Tang, NER_tag: B-PER\", \"Token: Shubei, NER_tag: I-PER\", \"Token: ,, NER_tag: O\", \"Token: executive, NER_tag: O\", \"Token: vice, NER_tag: O\", \"Token: chairman, NER_tag: O\", \"Token: of, NER_tag: O\", \"Token: the, NER_tag: O\", \"Token: Association, NER_tag: B-ORG\", \"Token: for, NER_tag: O\", \"Token: Relations, NER_tag: I-ORG\", \"Token: Across, NER_tag: I-ORG\", \"Token: the, NER_tag: O\", \"Token: Taiwan, NER_tag: B-LOC\", \"Token: Straits, NER_tag: I-LOC\", \"Token: ,, NER_tag: O\", \"Token: as, NER_tag: O\", \"Token: saying, NER_tag: O\", \"Token: late, NER_tag: O\", \"Token: on, NER_tag: O\", \"Token: Wednesday, NER_tag: O\", \"Token: ., NER_tag: O\"]\n</prompt>\n```",
            "```xml\n<instructions>\n    Transform the provided {input_data} into a list of tokens, each associated with its Named Entity Recognition (NER) label. Use the following NER labels: [I-LOC, B-ORG, O, B-PER, I-PER, I-MISC, B-MISC, I-ORG, B-LOC]. Structure the output in the same format as specified in the \"Desired Outputs.\"\n</instructions>\n<steps>\n    1. Analyze each token in {input_data} for its appropriate Named Entity Recognition label.\n    2. Format each token and its label as \"Token: {token}, NER_tag: {label}\".\n    3. Generate a list of these formatted strings for the entire {input_data}.\n    4. Ensure the output matches the \"Desired Outputs\" format exactly, with proper syntax and spacing.\n</steps>\n<example>\n    Inputs: `German July car registrations up 14.2 pct yr / yr . FRANKFURT 1996-08-22 German first-time registrations ...`\n    Desired Outputs: `[\"Token: German, NER_tag: B-LOC\", \"Token: July, NER_tag: O\", \"Token: car, NER_tag: O\", \"Token: registrations, NER_tag: O\", ...]`\n</example>\n<prompt>\n    Transform the provided input data \"German July car registrations up 14.2 pct yr / yr . FRANKFURT 1996-08-22 German first-time registrations of motor vehicles jumped 14.2 percent in July this year from the year-earlier period, the Federal office for motor vehicles said on Thursday. The office said 356,725 new cars were registered in July 1996 -- 304,850 passenger cars and 15,613 trucks. The figures represent a 13.6 percent increase for passenger cars and a 2.2 percent decline for trucks from July 1995. Motor-bike registration rose 32.7 percent in the period. The growth was partly due to an increased number of Germans buying German cars abroad, while manufacturers said that domestic demand was weak, the federal office said. Almost all German\" into a list of tokens, each associated with its Named Entity Recognition (NER) label. Use the labels [I-LOC, B-ORG, O, B-PER, I-PER, I-MISC, B-MISC, I-ORG, B-LOC]. \n</prompt>\n```",
            "```xml\n<prompt>\n    <instructions>\n        Create a structured output for the input data by labeling each token with the corresponding Named Entity Recognition (NER) tag.\n    </instructions>\n    <steps>\n        1. Analyze the input data: GREEK SOCIALISTS GIVE GREEN LIGHT TO PM FOR ELECTIONS . ATHENS 1996-08-22 The Greek socialist party 's executive bureau gave the green light to Prime Minister Costas Simitis to call snap elections , its general secretary Costas Skandalidis told reporters . Prime Minister Costas Simitis is going to make an official announcement after a cabinet meeting later on Thursday , said Skandalidis . -- Dimitris Kontogiannis , Athens Newsroom +301 3311812-4\n        2. Tokenize the input data and assign NER labels based on the context.\n    </steps>\n    <example>\n        Inputs: `GREEK SOCIALISTS GIVE GREEN LIGHT TO PM FOR ELECTIONS . ATHENS 1996-08-22 The Greek socialist party 's executive bureau gave the green light to Prime Minister Costas Simitis to call snap elections , its general secretary Costas Skandalidis told reporters . Prime Minister Costas Simitis is going to make an official announcement after a cabinet meeting later on Thursday , said Skandalidis . -- Dimitris Kontogiannis , Athens Newsroom +301 3311812-4`\n        Desired Outputs: `[\"Token: GREEK, NER_tag: B-LOC\", \"Token: SOCIALISTS, NER_tag: I-ORG\", \"Token: GIVE, NER_tag: O\", \"Token: GREEN, NER_tag: O\", \"Token: LIGHT, NER_tag: O\", \"Token: TO, NER_tag: O\", \"Token: PM, NER_tag: O\", \"Token: FOR, NER_tag: O\", \"Token: ELECTIONS, NER_tag: O\", \"Token: ., NER_tag: O\", \"Token: ATHENS, NER_tag: B-LOC\", \"Token: 1996-08-22, NER_tag: O\", \"Token: The, NER_tag: O\", \"Token: Greek, NER_tag: B-LOC\", \"Token: socialist, NER_tag: I-ORG\", \"Token: party, NER_tag: O\", \"Token: 's, NER_tag: O\", \"Token: executive, NER_tag: O\", \"Token: bureau, NER_tag: O\", \"Token: gave, NER_tag: O\", \"Token: the, NER_tag: O\", \"Token: green, NER_tag: O\", \"Token: light, NER_tag: O\", \"Token: to, NER_tag: O\", \"Token: Prime, NER_tag: B-PER\", \"Token: Minister, NER_tag: I-PER\", \"Token: Costas, NER_tag: B-PER\", \"Token: Simitis, NER_tag: I-PER\", \"Token: to, NER_tag: O\", \"Token: call, NER_tag: O\", \"Token: snap, NER_tag: O\", \"Token: elections, NER_tag: O\", \"Token: ,, NER_tag: O\", \"Token: its, NER_tag: O\", \"Token: general, NER_tag: O\", \"Token: secretary, NER_tag: O\", \"Token: Costas, NER_tag: B-PER\", \"Token: Skandalidis, NER_tag: I-PER\", \"Token: told, NER_tag: O\", \"Token: reporters, NER_tag: O\", \"Token: ., NER_tag: O\", \"Token: Prime, NER_tag: B-PER\", \"Token: Minister, NER_tag: I-PER\", \"Token: Costas, NER_tag: B-PER\", \"Token: Simitis, NER_tag: I-PER\", \"Token: is, NER_tag: O\", \"Token: going, NER_tag: O\", \"Token: to, NER_tag: O\", \"Token: make, NER_tag: O\", \"Token: an, NER_tag: O\", \"Token: official, NER_tag: O\", \"Token: announcement, NER_tag: O\", \"Token: after, NER_tag: O\", \"Token: a, NER_tag: O\", \"Token: cabinet, NER_tag: O\", \"Token: meeting, NER_tag: O\", \"Token: later, NER_tag: O\", \"Token: on, NER_tag: O\", \"Token: Thursday, NER_tag: O\", \"Token: ,, NER_tag: O\", \"Token: said, NER_tag: O\", \"Token: Skandalidis, NER_tag: I-PER\", \"Token: ., NER_tag: O\", \"Token: --, NER_tag: O\", \"Token: Dimitris, NER_tag: B-PER\", \"Token: Kontogiannis, NER_tag: I-PER\", \"Token: ,, NER_tag: O\", \"Token: Athens, NER_tag: B-LOC\", \"Token: Newsroom, NER_tag: O\", \"Token: +301, NER_tag: O\", \"Token: 3311812-4, NER_tag: O\"]`\n    </example>\n</prompt>\n```",
            "```xml\n<prompt>\n{\"Token\": \"BayerVB\", \"NER_tag\": \"B-ORG\"}, {\"Token\": \"sets\", \"NER_tag\": \"O\"}, {\"Token\": \"C$\", \"NER_tag\": \"O\"}, {\"Token\": \"100\", \"NER_tag\": \"O\"}, {\"Token\": \"million\", \"NER_tag\": \"O\"}, {\"Token\": \"six-year\", \"NER_tag\": \"O\"}, {\"Token\": \"bond\", \"NER_tag\": \"O\"}, {\"Token\": \".\", \"NER_tag\": \"O\"}, {\"Token\": \"LONDON\", \"NER_tag\": \"B-LOC\"}, {\"Token\": \"1996-08-22\", \"NER_tag\": \"O\"}, {\"Token\": \"The\", \"NER_tag\": \"O\"}, {\"Token\": \"following\", \"NER_tag\": \"O\"}, {\"Token\": \"bond\", \"NER_tag\": \"O\"}, {\"Token\": \"was\", \"NER_tag\": \"O\"}, {\"Token\": \"announced\", \"NER_tag\": \"O\"}, {\"Token\": \"by\", \"NER_tag\": \"O\"}, {\"Token\": \"lead\", \"NER_tag\": \"O\"}, {\"Token\": \"manager\", \"NER_tag\": \"O\"}, {\"Token\": \"Toronto\", \"NER_tag\": \"B-LOC\"}, {\"Token\": \"Dominion\", \"NER_tag\": \"I-LOC\"}, {\"Token\": \".\", \"NER_tag\": \"O\"}, {\"Token\": \"BORROWER\", \"NER_tag\": \"O\"}, {\"Token\": \"BAYERISCHE\", \"NER_tag\": \"B-ORG\"}, {\"Token\": \"VEREINSBANK\", \"NER_tag\": \"I-ORG\"}, {\"Token\": \"AMT\", \"NER_tag\": \"O\"}, {\"Token\": \"C$\", \"NER_tag\": \"O\"}, {\"Token\": \"100\", \"NER_tag\": \"O\"}, {\"Token\": \"MLN\", \"NER_tag\": \"O\"}, {\"Token\": \"COUPON\", \"NER_tag\": \"O\"}, {\"Token\": \"6.625\", \"NER_tag\": \"O\"}, {\"Token\": \"MATURITY\", \"NER_tag\": \"O\"}, {\"Token\": \"24.SEP.02\", \"NER_tag\": \"O\"}, {\"Token\": \"TYPE\", \"NER_tag\": \"O\"}, {\"Token\": \"STRAIGHT\", \"NER_tag\": \"O\"}, {\"Token\": \"ISS\", \"NER_tag\": \"O\"}, {\"Token\": \"PRICE\", \"NER_tag\": \"O\"}, {\"Token\": \"100.92\", \"NER_tag\": \"O\"}, {\"Token\": \"PAY\", \"NER_tag\": \"O\"}, {\"Token\": \"DATE\", \"NER_tag\": \"O\"}, {\"Token\": \"24.SEP.96\", \"NER_tag\": \"O\"}, {\"Token\": \"FULL\", \"NER_tag\": \"O\"}, {\"Token\": \"FEES\", \"NER_tag\": \"O\"}, {\"Token\": \"1.875\", \"NER_tag\": \"O\"}, {\"Token\": \"REOFFER\", \"NER_tag\": \"O\"}, {\"Token\": \"99.32\", \"NER_tag\": \"O\"}, {\"Token\": \"SPREAD\", \"NER_tag\": \"O\"}, {\"Token\": \"+20\", \"NER_tag\": \"O\"}, {\"Token\": \"BP\", \"NER_tag\": \"O\"}, {\"Token\": \"MOODY\", \"NER_tag\": \"B-ORG\"}, {\"Token\": \"AA1\", \"NER_tag\": \"O\"}, {\"Token\": \"LISTING\", \"NER_tag\": \"O\"}, {\"Token\": \"LUX\", \"NER_tag\": \"B-LOC\"}, {\"Token\": \"PAY\", \"NER_tag\": \"O\"}, {\"Token\": \"FREQ\", \"NER_tag\": \"O\"}, {\"Token\": \"=\", \"NER_tag\": \"O\"}, {\"Token\": \"S&P\", \"NER_tag\": \"B-ORG\"}, {\"Token\": \"=\", \"NER_tag\": \"O\"}, {\"Token\": \"DENOMS\", \"NER_tag\": \"O\"}, {\"Token\": \"(\", \"NER_tag\": \"O\"}, {\"Token\": \"K\", \"NER_tag\": \"O\"}, {\"Token\": \")\", \"NER_tag\": \"O\"}, {\"Token\": \"1-10-100\", \"NER_tag\": \"O\"}, {\"Token\": \"SALE\", \"NER_tag\": \"O\"}, {\"Token\": \"LIMITS\", \"NER_tag\": \"O\"}, {\"Token\": \"US\", \"NER_tag\": \"B-LOC\"}, {\"Token\": \"/\", \"NER_tag\": \"O\"}, {\"Token\": \"UK\", \"NER_tag\": \"B-LOC\"}, {\"Token\": \"/\", \"NER_tag\": \"O\"}, {\"Token\": \"CA\", \"NER_tag\": \"B-LOC\"}, {\"Token\": \"NEG\", \"NER_tag\": \"O\"}, {\"Token\": \"PLG\", \"NER_tag\": \"O\"}, {\"Token\": \"NO\", \"NER_tag\": \"O\"}, {\"Token\": \"CRS\", \"NER_tag\": \"O\"}, {\"Token\": \"DEFLT\", \"NER_tag\": \"O\"}, {\"Token\": \"NO\", \"NER_tag\": \"O\"}, {\"Token\": \"FORCE\", \"NER_tag\": \"O\"}, {\"Token\": \"MAJ\", \"NER_tag\": \"O\"}, {\"Token\": \"=\", \"NER_tag\": \"O\"}, {\"Token\": \"GOV\", \"NER_tag\": \"O\"}, {\"Token\": \"LAW\", \"NER_tag\": \"O\"}, {\"Token\": \"GERMAN\", \"NER_tag\": \"B-LOC\"}, {\"Token\": \"HOME\", \"NER_tag\": \"O\"}, {\"Token\": \"CTRY\", \"NER_tag\": \"O\"}, {\"Token\": \"=\", \"NER_tag\": \"O\"}, {\"Token\": \"TAX\", \"NER_tag\": \"O\"}, {\"Token\": \"PROVS\", \"NER_tag\": \"O\"}, {\"Token\": \"STANDARD\", \"NER_tag\": \"O\"}, {\"Token\": \"MGT\", \"NER_tag\": \"O\"}, {\"Token\": \"/\", \"NER_tag\": \"O\"}, {\"Token\": \"UND\", \"NER_tag\": \"O\"}, {\"Token\": \"0.275\", \"NER_tag\": \"O\"}, {\"Token\": \"SELL\", \"NER_tag\": \"O\"}, {\"Token\": \"CONC\", \"NER_tag\": \"O\"}, {\"Token\": \"1.60\", \"NER_tag\": \"O\"}, {\"Token\": \"PRAECIP\", \"NER_tag\": \"O\"}, {\"Token\": \"=\", \"NER_tag\": \"O\"}, {\"Token\": \"UNDERLYING\", \"NER_tag\": \"O\"}, {\"Token\": \"GOVT\", \"NER_tag\": \"O\"}, {\"Token\": \"BOND\", \"NER_tag\": \"O\"}, {\"Token\": \"7.0\", \"NER_tag\": \"O\"}, {\"Token\": \"PCT\", \"NER_tag\": \"O\"}, {\"Token\": \"SEPT\", \"NER_tag\": \"O\"}, {\"Token\": \"2001\", \"NER_tag\": \"O\"}, {\"Token\": \"NOTES\", \"NER_tag\": \"O\"}, {\"Token\": \"BAYERISCHE\", \"NER_tag\": \"B-ORG\"}, {\"Token\": \"VEREINSBANK\", \"NER_tag\": \"I-ORG\"}, {\"Token\": \"IS\", \"NER_tag\": \"O\"}, {\"Token\": \"JOINT\", \"NER_tag\": \"O\"}, {\"Token\": \"LEAD\", \"NER_tag\": \"O\"}, {\"Token\": \"MANAGER\", \"NER_tag\": \"O\"}, {\"Token\": \"--\", \"NER_tag\": \"O\"}, {\"Token\": \"London\", \"NER_tag\": \"B-LOC\"}, {\"Token\": \"Newsroom\", \"NER_tag\": \"O\"}, {\"Token\": \"+44\", \"NER_tag\": \"O\"}, {\"Token\": \"171\", \"NER_tag\": \"O\"}, {\"Token\": \"542\", \"NER_tag\": \"O\"}, {\"Token\": \"7658\", \"NER_tag\": \"O\"}\n</prompt>\n```",
            "```xml\n<instructions> \n1. **Objective**: Create a structured prompt to instruct an LLM to transform the provided \"Inputs\" into the exact format of the \"Desired Outputs.\" \n2. **Use of Tags**: Ensure each section of your prompt is wrapped with the appropriate XML tags: \n- Wrap instructions in &lt;instructions&gt;...&lt;/instructions&gt; \n- Wrap steps in &lt;steps&gt;...&lt;/steps&gt; \n- Wrap examples in &lt;example&gt;...&lt;/example&gt; \n- Wrap the final system prompt in &lt;prompt&gt;...&lt;/prompt&gt; \n3. **Maintain Structure**: Follow the specified XML tags consistently to ensure clarity and parseability. \n4. **Independent Processing**: Treat each input-output pair as independent, ensuring that no input is merged or inferred with another. \n5. **Use of {input_data} Placeholder**: Use the placeholder {input_data} **only** for variables that need to be substituted dynamically. Ensure that each row's data is processed independently, but avoid using the placeholder for fixed data or values that do not change between rows. \n6. **Output Fidelity**: The output should exactly match the \"Desired Outputs,\" including syntax, spacing, and characters, with no deviations or added commentary. \n</instructions> \n<steps> \n1. Analyze each row in \"Inputs\" and map it to the corresponding format specified in \"Desired Outputs.\" \n2. Use the placeholder {input_data} **only** for variables that need to be substituted dynamically. Avoid using this placeholder for fixed values or data that will not change between rows unless it is used in \"Desired Outputs\". \n3. Ensure each output follows the same syntax, spacing, and special characters as the \"Desired Outputs.\" \n4. Utilize information in context since there might be important information the user is specifying. \n5. The **generated system prompt must be wrapped in the &lt;prompt&gt;...&lt;/prompt&gt; tags**. \n6. Do not include any commentary, explanations, or metadata\u2014just the final system prompt in the required structure. \n</steps> \n<example> \nInputs: `0 Venantius sets $ 300 million January 1999 FRN . LONDON 1996-08-22 The following floating-rate issue was announced by lead manager Lehman Brothers International . BORROWER VENANTIUS AB ( SWEDISH NATIONAL MORTGAGE AGENCY ) AMT $ 300 MLN SPREAD - 12.5 BP MATURITY 21.JAN.99 TYPE FRN BASE 3M LIBOR PAY DATE S23.SEP.96 LAST MOODY AA3 ISS PRICE 99.956 FULL FEES 10 BP LAST S&P AA+ REOFFER = NOTES S SHORT FIRST COUPON LISTING LONDON DENOMS ( K ) 1-10-100 SALE LIMITS US / UK / JP / FR NEG PLG YES CRS DEFLT NO FORCE MAJ IPMA 2 GOV LAW ENGLISH HOME CTRY SWEDEN TAX PROVS STANDARD MGT / UND 5 BP SELL CONC 5 BP PRAECIP = NOTES ISSUED OFF EMTN PROGRAMME --`\nDesired Outputs: `0 [\"Token: Venantius, NER_tag: B-ORG\", \"Token: sets, NER_tag: O\", \"Token: $, NER_tag: O\", \"Token: 300, NER_tag: O\", \"Token: million, NER_tag: O\", \"Token: January, NER_tag: O\", \"Token: 1999, NER_tag: O\", \"Token: FRN, NER_tag: O\", \"Token: ., NER_tag: O\", \"Token: LONDON, NER_tag: B-LOC\", \"Token: 1996-08-22, NER_tag: O\", \"Token: The, NER_tag: O\", \"Token: following, NER_tag: O\", \"Token: floating-rate, NER_tag: O\", \"Token: issue, NER_tag: O\", \"Token: was, NER_tag: O\", \"Token: announced, NER_tag: O\", \"Token: by, NER_tag: O\", \"Token: lead, NER_tag: O\", \"Token: manager, NER_tag: O\", \"Token: Lehman, NER_tag: B-ORG\", \"Token: Brothers, NER_tag: I-ORG\", \"Token: International, NER_tag: I-ORG\", \"Token: ., NER_tag: O\", \"Token: BORROWER, NER_tag: O\", \"Token: VENANTIUS, NER_tag: B-ORG\", \"Token: AB, NER_tag: O\", \"Token: (, NER_tag: O\", \"Token: SWEDISH, NER_tag: B-LOC\", \"Token: NATIONAL, NER_tag: O\", \"Token: MORTGAGE, NER_tag: O\", \"Token: AGENCY, NER_tag: O\", \"Token: ), NER_tag: O\", \"Token: AMT, NER_tag: O\", \"Token: $, NER_tag: O\", \"Token: 300, NER_tag: O\", \"Token: MLN, NER_tag: O\", \"Token: SPREAD, NER_tag: O\", \"Token: -, NER_tag: O\", \"Token: 12.5, NER_tag: O\", \"Token: BP, NER_tag: O\", \"Token: MATURITY, NER_tag: O\", \"Token: 21.JAN.99, NER_tag: O\", \"Token: TYPE, NER_tag: O\", \"Token: FRN, NER_tag: O\", \"Token: BASE, NER_tag: O\", \"Token: 3M, NER_tag: O\", \"Token: LIBOR, NER_tag: O\", \"Token: PAY, NER_tag: O\", \"Token: DATE, NER_tag: O\", \"Token: S23.SEP.96, NER_tag: O\", \"Token: LAST, NER_tag: O\", \"Token: MOODY, NER_tag: O\", \"Token: AA3, NER_tag: O\", \"Token: ISS, NER_tag: O\", \"Token: PRICE, NER_tag: O\", \"Token: 99.956, NER_tag: O\", \"Token: FULL, NER_tag: O\", \"Token: FEES, NER_tag: O\", \"Token: 10, NER_tag: O\", \"Token: BP, NER_tag: O\", \"Token: LAST, NER_tag: O\", \"Token: S&P, NER_tag: O\", \"Token: AA+, NER_tag: O\", \"Token: REOFFER, NER_tag: O\", \"Token: =, NER_tag: O\", \"Token: NOTES, NER_tag: O\", \"Token: S, NER_tag: O\", \"Token: SHORT, NER_tag: O\", \"Token: FIRST, NER_tag: O\", \"Token: COUPON, NER_tag: O\", \"Token: LISTING, NER_tag: O\", \"Token: LONDON, NER_tag: B-LOC\", \"Token: DENOMS, NER_tag: O\", \"Token: (, NER_tag: O\", \"Token: K, NER_tag: O\", \"Token: ), NER_tag: O\", \"Token: 1-10-100, NER_tag: O\", \"Token: SALE, NER_tag: O\", \"Token: LIMITS, NER_tag: O\", \"Token: US, NER_tag: B-LOC\", \"Token: /, NER_tag: O\", \"Token: UK, NER_tag: B-LOC\", \"Token: /, NER_tag: O\", \"Token: JP, NER_tag: B-LOC\", \"Token: /, NER_tag: O\", \"Token: FR, NER_tag: B-LOC\", \"Token: NEG, NER_tag: O\", \"Token: PLG, NER_tag: O\", \"Token: YES, NER_tag: O\", \"Token: CRS, NER_tag: O\", \"Token: DEFLT, NER_tag: O\", \"Token: NO, NER_tag: O\", \"Token: FORCE, NER_tag: O\", \"Token: MAJ, NER_tag: O\", \"Token: IPMA, NER_tag: O\", \"Token: 2, NER_tag: O\", \"Token: GOV, NER_tag: O\", \"Token: LAW, NER_tag: O\", \"Token: ENGLISH, NER_tag: O\", \"Token: HOME, NER_tag: O\", \"Token: CTRY, NER_tag: O\", \"Token: SWEDEN, NER_tag: B-LOC\", \"Token: TAX, NER_tag: O\", \"Token: PROVS, NER_tag: O\", \"Token: STANDARD, NER_tag: O\", \"Token: MGT, NER_tag: O\", \"Token: /, NER_tag: O\", \"Token: UND, NER_tag: O\", \"Token: 5, NER_tag: O\", \"Token: BP, NER_tag: O\", \"Token: SELL, NER_tag: O\", \"Token: CONC, NER_tag: O\", \"Token: 5, NER_tag: O\", \"Token: BP, NER_tag: O\", \"Token: PRAECIP, NER_tag: O\", \"Token: =, NER_tag: O\", \"Token: NOTES, NER_tag: O\", \"Token: ISSUED, NER_tag: O\", \"Token: OFF, NER_tag: O\", \"Token: EMTN, NER_tag: O\", \"Token: PROGRAMME, NER_tag: O\", \"Token: --, NER_tag: O\"] \n</example> \n<prompt> \nTransform the following input text into a structured format with Named Entity Recognition (NER) labels. Each word/token in the text must be labeled according to its NER category, using the specified format. For example, a person\u2019s name should be labeled with B-PER or I-PER, a location with B-LOC or I-LOC, and organization names with B-ORG or I-ORG. If a token does not fit any of these categories, label it as O. Please process the following input independently: {input_data}. \n</prompt>\n```",
            "<prompt>Transform the input data into the desired output format. Use the following data: {input_data} = Port conditions update - Syria - Lloyds Shipping . Port conditions from Lloyds Shipping Intelligence Service -- LATTAKIA , Aug 10 - waiting time at Lattakia and Tartous presently 24 hours . \n\nOutput the following:\n[\"Token: Port, NER_tag: O\", \"Token: conditions, NER_tag: O\", \"Token: update, NER_tag: O\", \"Token: -, NER_tag: O\", \"Token: Syria, NER_tag: B-LOC\", \"Token: -, NER_tag: O\", \"Token: Lloyds, NER_tag: B-ORG\", \"Token: Shipping, NER_tag: I-ORG\", \"Token: ., NER_tag: O\", \"Token: Port, NER_tag: O\", \"Token: conditions, NER_tag: O\", \"Token: from, NER_tag: O\", \"Token: Lloyds, NER_tag: B-ORG\", \"Token: Shipping, NER_tag: I-ORG\", \"Token: Intelligence, NER_tag: I-ORG\", \"Token: Service, NER_tag: I-ORG\", \"Token: --, NER_tag: O\", \"Token: LATTAKIA, NER_tag: B-LOC\", \"Token: ,, NER_tag: O\", \"Token: Aug, NER_tag: B-MISC\", \"Token: 10, NER_tag: O\", \"Token: -, NER_tag: O\", \"Token: waiting, NER_tag: O\", \"Token: time, NER_tag: O\", \"Token: at, NER_tag: O\", \"Token: Lattakia, NER_tag: B-LOC\", \"Token: and, NER_tag: O\", \"Token: Tartous, NER_tag: B-LOC\", \"Token: presently, NER_tag: O\", \"Token: 24, NER_tag: O\", \"Token: hours, NER_tag: O\", \"Token: ., NER_tag: O\"]</prompt>",
            "```xml\n<instructions>\n  Create a structured prompt to instruct a language model to transform the provided input data into the exact format of the desired output. \n</instructions>\n<steps>\n  1. Analyze each row in \"Inputs\" and map it to the corresponding format specified in \"Desired Outputs.\"\n  2. Use the placeholder {input_data} only for variables that need to be substituted dynamically. Avoid using this placeholder for fixed values or data that will not change between rows unless it is used in \"Desired Outputs\".\n  3. Ensure each output follows the same syntax, spacing, and special characters as the \"Desired Outputs.\"\n  4. Utilize information in context since there might be important information the user is specifying.\n  5. The generated system prompt must be wrapped in the <prompt>...<prompt> tags.\n  6. Do not include any commentary, explanations, or metadata\u2014just the final system prompt in the required structure.\n</steps>\n<example>\n  Inputs: `0 EU rejects German call to boycott British lamb... 1 Rare Hendrix song draft sells for almost $ 17,... Name: input_data, dtype: object`\n  Desired Outputs: `0 [\"Token: EU, NER_tag: B-ORG\", \"Token: rejects,... 1 [\"Token: Rare, NER_tag: O\", \"Token: Hendrix, N... Name: desired_output, dtype: object`\n</example>\n<context>\n  The input data is raw tokenized text, and the desired output consists of tokens with their Named Entity Recognition label. The Tokens are labeled under one of the following labels [I-LOC, B-ORG, O, B-PER, I-PER, I-MISC, B-MISC, I-ORG, B-LOC]. The goal is to label all the tokens with their NER label.\n</context>\n<prompt>\n  Transform the following input data into tokens with their Named Entity Recognition labels: {input_data}\n</prompt>\n```",
            "```xml\n<instructions>\n1. **Objective**: Create a structured prompt to instruct an LLM to transform the provided \"Inputs\" into the exact format of the \"Desired Outputs.\"\n2. **Use of Tags**: Ensure each section of your prompt is wrapped with the appropriate XML tags: \n   - Wrap instructions in &lt;instructions&gt;...&lt;/instructions&gt; \n   - Wrap steps in &lt;steps&gt;...&lt;/steps&gt; \n   - Wrap examples in &lt;example&gt;...&lt;/example&gt; \n   - Wrap the final system prompt in &lt;prompt&gt;...&lt;/prompt&gt;\n3. **Maintain Structure**: Follow the specified XML tags consistently to ensure clarity and parseability.\n4. **Independent Processing**: Treat each input-output pair as independent, ensuring that no input is merged or inferred with another.\n5. **Use of {input_data} Placeholder**: Use the placeholder {input_data} **only** for variables that need to be substituted dynamically. Ensure that each row's data is processed independently, but avoid using the placeholder for fixed data or values that do not change between rows. \n6. **Output Fidelity**: The output should exactly match the \"Desired Outputs,\" including syntax, spacing, and characters, with no deviations or added commentary.\n</instructions>\n<steps>\n1. Analyze each row in \"Inputs\" and map it to the corresponding format specified in \"Desired Outputs.\"\n2. Use the placeholder {input_data} **only** for variables that need to be substituted dynamically. Avoid using this placeholder for fixed values or data that will not change between rows unless it is used in \"Desired Outputs\".\n3. Ensure each output follows the same syntax, spacing, and special characters as the \"Desired Outputs.\"\n4. Utilize information in context since there might be important information the user is specifying.\n5. The **generated system prompt must be wrapped in the &lt;prompt&gt;...&lt;/prompt&gt; tags**.\n6. Do not include any commentary, explanations, or metadata\u2014just the final system prompt in the required structure.\n</steps>\n<example>\nInputs: `{input_data}`\nDesired Outputs: `[\"Token: Polish, NER_tag: B-LOC\", \"Token: diplomat, NER_tag: O\", \"Token: denies, NER_tag: O\", ...]`\n</example>\n<context>\n**Context**: Input data is raw tokenized text, and the desired output consists of tokens with their Named Entity Recognition label. The Tokens are labeled under one of the following labels [I-LOC, B-ORG, O, B-PER, I-PER, I-MISC, B-MISC, I-ORG, B-LOC]. The goal is to label all the tokens with its NER label.\n</context>\n<prompt>\nTransform the input data `{input_data}` into a structured JSON format where each token is labeled with its Named Entity Recognition (NER) tag. Follow the requirements of using specific tags for the NER classification and ensure the output matches the format specified in the Desired Outputs.\n</prompt>\n```",
            "```xml\n<instructions>\n1. Analyze each row in \"Inputs\" and map it to the corresponding format specified in \"Desired Outputs.\"\n2. Use the placeholder {input_data} **only** for variables that need to be substituted dynamically. Avoid using this placeholder for fixed values or data that will not change between rows unless it is used in \"Desired Outputs\".\n3. Ensure each output follows the same syntax, spacing, and special characters as the \"Desired Outputs.\"\n4. Utilize information in context since there might be important information the user is specifying.\n5. The **generated system prompt must be wrapped in the &lt;prompt&gt;...&lt;/prompt&gt; tags**.\n6. Do not include any commentary, explanations, or metadata\u2014just the final system prompt in the required structure.\n</instructions>\n<steps>\n1. Analyze each row in \"Inputs\" and map it to the corresponding format specified in \"Desired Outputs.\"\n2. Use the placeholder {input_data} **only** for variables that need to be substituted dynamically. Avoid using this placeholder for fixed values or data that will not change between rows unless it is used in \"Desired Outputs\".\n3. Ensure each output follows the same syntax, spacing, and special characters as the \"Desired Outputs.\"\n4. Utilize information in context since there might be important information the user is specifying.\n5. The **generated system prompt must be wrapped in the &lt;prompt&gt;...&lt;/prompt&gt; tags**.\n6. Do not include any commentary, explanations, or metadata\u2014just the final system prompt in the required structure.\n</steps>\n<example>\nInputs: `0 Two Iranian opposition leaders meet in Baghdad... Name: input_data, dtype: object`\nDesired Outputs: `0 [\"Token: Two, NER_tag: O\", \"Token: Iranian, NER_tag: B-MISC\", \"Token: opposition, NER_tag: O\", \"Token: leaders, NER_tag: O\", \"Token: meet, NER_tag: O\", \"Token: in, NER_tag: O\", \"Token: Baghdad, NER_tag: I-LOC\", ...  Name: desired_output, dtype: object`\n</example>\n<prompt>\nTransform the input {input_data} into the following format: [\"Token: Two, NER_tag: O\", \"Token: Iranian, NER_tag: B-MISC\", \"Token: opposition, NER_tag: O\", \"Token: leaders, NER_tag: O\", \"Token: meet, NER_tag: O\", \"Token: in, NER_tag: O\", \"Token: Baghdad, NER_tag: I-LOC\", \"Token: ..., NER_tag: ...\"]\n</prompt>\n```"
        ]
    }
}